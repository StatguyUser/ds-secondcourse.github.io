<!DOCTYPE html>
<html lang="" xml:lang="">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 | Feature Engineering & Selection for Explainable Models A Second Course for Data Scientists
  </title>


  <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
  <link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
  <link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
  <link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
  <script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
  <script src="libs/kePrint-0.0.1/kePrint.js"></script>
  <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
  <!-- Global site tag (gtag.js) - Google Analytics -->


  <link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
  <script src="javascript/cookieconsent.min.js"></script>
  <script>
    window.addEventListener("load", function () {
      window.cookieconsent.initialise({
        "palette": {
          "popup": {
            "background": "#000"
          },
          "button": {
            "background": "#f1d600"
          }
        },
        "position": "bottom-right",
        "content": {
          "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
        }
      })
    });
  </script>

  <style>
    #cta-button-desktop:hover,
    #cta-button-device:hover {
      background-color: #ffc266;
      border-color: #ffc266;
      box-shadow: none;
    }

    #cta-button-desktop,
    #cta-button-device {
      color: white;
      background-color: #ffa31a;
      text-shadow: 1px 1px 0 #444;
      text-decoration: none;
      border: 2px solid #ffa31a;
      border-radius: 10px;
      position: fixed;
      padding: 5px 10px;
      z-index: 10;
    }

    #cta-button-device {
      box-shadow: 0px 10px 10px -5px rgba(194, 180, 190, 1);
      display: none;
      right: 20px;
      bottom: 20px;
      font-size: 20px;
    }

    #cta-button-desktop {
      box-shadow: 0px 20px 20px -10px rgba(194, 180, 190, 1);
      display: display;
      padding: 8px 16px;
      right: 40px;
      bottom: 40px;
      font-size: 25px;
    }

    @media (max-width : 450px) {
      #cta-button-device {
        display: block;
      }

      #cta-button-desktop {
        display: none;
      }
    }
  </style>






  <link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">
    <div class="book-summary">
      <nav role="navigation">

        <ul class="summary">
          <li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i
                class="fa fa-check"></i>Summary</a></li>
          <li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a href="foreward.html"><i
                class="fa fa-check"></i>Foreward</a></li>
          <li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a
              href="preface-by-the-author.html"><i class="fa fa-check"> </i>Preface</a></li>
          <li class="chapter" data-level="1" data-path="intro.html"><a href="before-we-start.html"><i
                class="fa fa-check"></i>Before we start</a></li>
          <li class="chapter" data-level="1"><a href="section01.html"><i class="fa fa-check"></i>Section I:
              Introduction</a>

          <li class="chapter" data-level="1"><a href="chapter01.html"><i class="fa fa-check"></i>1: Introduction</a>
          </li>

          <ul>
            <li class="chapter" data-level="2"><a href="chapter0101.html"><i class="fa fa-check"></i>1.1:
                Terminology</a></li>
            <li class="chapter" data-level="2"><a href="chapter0102.html"><i class="fa fa-check"></i>1.2: Process of
                Training a Machine Learning Model</a></li>
            <li class="chapter" data-level="2"><a href="chapter0103.html"><i class="fa fa-check"></i>1.3: Preventing
                Overfitting</a></li>
            <li class="chapter" data-level="2"><a href="chapter0104.html"><i class="fa fa-check"></i>1.4: Code
                Conventions</a></li>
            <li class="chapter" data-level="2"><a href="chapter0105.html"><i class="fa fa-check"></i>1.5: Datasets
                Used</a></li>
            <li class="chapter" data-level="2"><a href="chapter0106.html"><i class="fa fa-check"></i>1.6:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="section02.html"><i class="fa fa-check"></i>Section II:
              Feature Engineering</a>
          <li class="chapter" data-level="1"><a href="chapter02.html"><i class="fa fa-check"></i>2: Domain Specific
              Feature Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="chapter02.html"><i class="fa fa-check"></i>2.1:
                Introduction</a></li>
            <li class="chapter" data-level="2"><a href="chapter0202.html"><i class="fa fa-check"></i>2.2:
                Domain-Specific Feature Engineering </a></li>
            <li class="chapter" data-level="2"><a href="chapter0203.html"><i class="fa fa-check"></i>2.3:
                References</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="chapter03.html"><i class="fa fa-check"></i>3: EDA Feature
              Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="chapter03.html"><i class="fa fa-check"></i>3.1:
                Introduction</a></li>
            <li class="chapter" data-level="2"><a href="chapter0302.html"><i class="fa fa-check"></i>3.2: Car Sales
              </a></li>
            <li class="chapter" data-level="2"><a href="chapter0303.html"><i class="fa fa-check"></i>3.3: Coupon
                Recommendation</a></li>
            <li class="chapter" data-level="2"><a href="chapter0304.html"><i class="fa fa-check"></i>3.4:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="chapter04.html"><i class="fa fa-check"></i>4: Higher Order
              Feature Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="chapter0401.html"><i class="fa fa-check"></i>4.1:
                Engineering Categorical Features</a></li>
            <li class="chapter" data-level="2"><a href="chapter0402.html"><i class="fa fa-check"></i>4.2:
                Engineering Ordinal Features </a></li>
            <li class="chapter" data-level="2"><a href="chapter0403.html"><i class="fa fa-check"></i>4.3:
                Engineering Numerical Features</a></li>
            <li class="chapter" data-level="2"><a href="chapter0404.html"><i class="fa fa-check"></i>4.4:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="2"><a href="chapter05.html"><i class="fa fa-check"></i>5: Interaction
              Effect Feature Engineering</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter0501.html"><i class="fa fa-check"></i>5.1:
                Interaction Plot</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter0502.html"><i class="fa fa-check"></i>5.2: SHAP</a>
            </li>
            <li class="chapter" data-level="2.3"><a href="chapter0503.html"><i class="fa fa-check"></i>5.3: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0504.html"><i class="fa fa-check"></i>5.4:
                Conclusion</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0505.html"><i class="fa fa-check"></i>5.5:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="section03.html"><i class="fa fa-check"></i>Section III:
              Feature Selection</a>
          <li class="chapter" data-level="1"><a href="chapter06.html"><i class="fa fa-check"></i>6: Fundamentals of
              Feature Selection</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter06.html"><i class="fa fa-check"></i>6.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter0602.html"><i class="fa fa-check"></i>6.2: Different
                Feature Selection Methods</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0603.html"><i class="fa fa-check"></i>6.3: Filter
                Method</a></li>
            <li class="chapter" data-level="2.4"><a href="chapter0604.html"><i class="fa fa-check"></i>6.4: Wrapper
                Method</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0605.html"><i class="fa fa-check"></i>6.5: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0606.html"><i class="fa fa-check"></i>6.6:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="chapter07.html"><i class="fa fa-check"></i>7: Feature
              Selection Concerning Modeling Techniques</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter0701.html"><i class="fa fa-check"></i>7.1:
                Lasso, Ridge, and ElasticNet</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter0702.html"><i class="fa fa-check"></i>7.2: Feature
                Importance of Tree Models</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0703.html"><i class="fa fa-check"></i>7.3: Boruta</a>
            </li>
            <li class="chapter" data-level="2.4"><a href="chapter0704.html"><i class="fa fa-check"></i>7.4: Using
                Tree-Based Feature Importance for Linear Model</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0705.html"><i class="fa fa-check"></i>7.5: Using
                Linear Model Feature Importance for Tree Models</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0706.html"><i class="fa fa-check"></i>7.6: Linear
                Regression</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0707.html"><i class="fa fa-check"></i>7.7: SVM</a>
            </li>
            <li class="chapter" data-level="2.5"><a href="chapter0708.html"><i class="fa fa-check"></i>7.8: PCA</a>
            </li>
            <li class="chapter" data-level="2.5"><a href="chapter0709.html"><i class="fa fa-check"></i>7.9: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0710.html"><i class="fa fa-check"></i>7.10:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="chapter08.html"><i class="fa fa-check"></i>8: Feature
              Selection Using Metaheuristic Algorithms</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter0801.html"><i class="fa fa-check"></i>8.1: Exhaustive
                Feature Selection</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter0802.html"><i class="fa fa-check"></i>8.2: Genetic
                Algorithm</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0803.html"><i class="fa fa-check"></i>8.3: Simulated
                Annealing</a></li>
            <li class="chapter" data-level="2.4"><a href="chapter0804.html"><i class="fa fa-check"></i>8.4: Ant Colony
                Optimization</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0805.html"><i class="fa fa-check"></i>8.5: Particle
                Swarm Optimization</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0806.html"><i class="fa fa-check"></i>8.6: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0807.html"><i class="fa fa-check"></i>8.7:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0808.html"><i class="fa fa-check"></i>8.8:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="section04.html"><i class="fa fa-check"></i>Section IV:
              Model Explanation</a>
          <li class="chapter" data-level="1"><a href="chapter09.html"><i class="fa fa-check"></i>9: Explaining Model
              and Model Predictions to Layman</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter09.html"><i class="fa fa-check"></i>9.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter0902.html"><i class="fa fa-check"></i>9.2:
                Explainable models</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter0903.html"><i class="fa fa-check"></i>9.3:
                Explanation Techniques</a></li>
            <li class="chapter" data-level="2.4"><a href="chapter0904.html"><i class="fa fa-check"></i>9.4: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0905.html"><i class="fa fa-check"></i>9.5:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter0906.html"><i class="fa fa-check"></i>9.6:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="section05.html"><i class="fa fa-check"></i>Section V:
              Special Chapters</a>
          <li class="chapter" data-level="2"><a href="chapter10.html"><i class="fa fa-check"></i>10: Feature
              Engineering & Selection for Text Classification</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter10.html"><i class="fa fa-check"></i>10.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter1002.html"><i class="fa fa-check"></i>10.2: Feature
                Construction</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter1003.html"><i class="fa fa-check"></i>10.3: Feature
                Selection</a></li>
            <li class="chapter" data-level="2.4"><a href="chapter1004.html"><i class="fa fa-check"></i>10.4: Feature
                Extraction</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter1005.html"><i class="fa fa-check"></i>10.5: Feature
                Reduction</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter1006.html"><i class="fa fa-check"></i>10.6:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter1007.html"><i class="fa fa-check"></i>10.7:
                References</a></li>
          </ul>
          <li class="chapter" data-level="2"><a href="chapter11.html"><i class="fa fa-check"></i>11: Things That Can
              Give Additional Improvement</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="chapter11.html"><i class="fa fa-check"></i>11.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="chapter1102.html"><i class="fa fa-check"></i>11.2:
                Hyperparameter Tuning</a></li>
            <li class="chapter" data-level="2.3"><a href="chapter1103.html"><i class="fa fa-check"></i>11.3: Ensemble
                Learning</a></li>
            <li class="chapter" data-level="2.4"><a href="chapter1104.html"><i class="fa fa-check"></i>11.4: Signal
                Processing</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter1105.html"><i class="fa fa-check"></i>11.5:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="chapter1106.html"><i class="fa fa-check"></i>11.6:
                References</a></li>
          </ul>
          </li>
        </ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
              <div id="forward-by-the-author" class="section level1 hasAnchor" number="1">
                <h1><span class="header-section-number">Chapter 8:</span> Feature Selection Using Metaheuristic
                  Algorithms</h1>
                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Each feature in a dataset can have a
                    main effect and an interaction effect, because of which, different combinations
                    of features have varying model performance. This makes feature selection an
                    inherently combinatorial problem. We need to find the combination of features
                    that gives the best model performance. As the number of features keeps
                    increasing, the number of possible combinations keeps increasing, and so does
                    the computational cost of trying all the possible combinations. Metaheuristic
                    algorithms can help us solve this problem by searching for a limited and lesser
                    number of solutions. It does so by searching for better solutions iteratively.
                    At the beginning of the algorithm, it starts with randomly generated solutions
                    and tries to improve the solution at each iteration. Metaheuristic algorithms
                    are procedures that can find a good solution for optimization problems, which
                    are difficult and complex otherwise to solve manually. These partial search
                    algorithms may provide a good enough solution, if not a perfect solution. These
                    are very useful for feature selection, as they can help us find better feature
                    sets than otherwise possible through manually trying different combinations.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>We will discuss 4 metaheuristics
                    algorithms in this chapter. These are genetic algorithm, simulated annealing,
                    ant colony optimization, and particle swarm optimization. We have developed a
                    companion python library <span style='color:white;background:#333333'>MetaheuristicsFS</span>,
                    which has all 4 metaheuristics feature selection algorithms. Its module <span
                      style='color:white;background:#333333'>FeatureSelection</span> helps us perform
                    the desired feature selection.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Some parameters are common across
                    all metaheuristic algorithms in this library. For example, cross-validation
                    dataset, validation data set, and name of all input features. Imagine a
                    scenario where you want to try multiple metaheuristic algorithms. You will need
                    to enter these common parameters repeatedly for all the algorithms separately.
                    To avoid this situation, we have used the &nbsp;singleton&nbsp; approach in the <span
                      style='color:white;background:#333333'>MetaheuristicsFS</span> library. The
                    first step creates a feature selection object by providing common input
                    parameters. In the second step, we can initialize any desired metaheuristic
                    algorithm from the 4 listed algorithms. We will discuss this in the subsequent
                    sections.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>First, we will import the <span
                      style='color:white;background:#333333'>FeatureSelection</span> module from the
                    MetaheuristicsFS python library using the below syntax.<o:p></o:p></span></p>

                <table class=a6 border=0 cellspacing=0 cellpadding=0 width=624 style='border-collapse:collapse;mso-table-layout-alt:fixed;mso-yfti-tbllook:
 1536;mso-padding-alt:5.0pt 5.0pt 5.0pt 5.0pt'>
                  <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
                    <td width=624 valign=top style='width:468.0pt;background:#333333;padding:
  5.0pt 5.0pt 5.0pt 5.0pt'>
                      <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
  8.0pt;margin-left:0cm;line-height:150%;mso-pagination:none;border:none;
  mso-padding-alt:31.0pt 31.0pt 31.0pt 31.0pt;mso-border-shadow:yes'><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>from</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> MetaheuristicsFS </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#FCC28C;background:#333333'>import</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> FeatureSelection</span><span lang=EN
                          style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'>
                          <o:p></o:p>
                        </span></p>
                    </td>
                  </tr>
                </table>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Let&nbsp;s understand all the required
                    input fields for the module FeatureSelection.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>columns_list</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: It is a python list object and contains the names of all
                    the features as strings, separated by a comma. These feature names are present
                    in the training, test, validation, and external validation datasets. For
                    example, if there are 3 features x1, x2, and x3, it will be represented as
                    columns_list = [&nbsp;x1&nbsp;, &nbsp;x2&nbsp;, &nbsp;x3&nbsp;]. Based on this input list of
                    features, search
                    algorithms create different combinations, to find the best possible feature
                    combination.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>data_dict</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: It is a python dictionary object and contains training and
                    test data for multiple cross-validations.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Its key represents each unique
                    cross-validation. For example, 0,1,2,3,4 represent 5 separate
                    cross-validations. If a user wants to perform 5-fold cross-validation,
                    data_dict should have 5 key-value pairs with 0,1,2,3, and 4 as keys. Each pair
                    is created by shuffling the dataframe and splitting into train and test.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Each key has a nested dictionary
                    containing training and test data. The value against each cross-validation key
                    is a nested dictionary and contains features and dependent variables as a
                    dataframe object. Key '<span class=SpellE>x_train</span>', and '<span class=SpellE>x_test</span>'
                    contain feature dataframe for training and test
                    data as value pairs. Similarly, the '<span class=SpellE>y_train</span>', and '<span
                      class=SpellE>y_test</span>' key contains a dependent variable as a dataframe
                    object for training, and test data respectively.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Below is what the dictionary
                    structure looks like for 2-fold cross-validations.<o:p></o:p></span></p>

                <table class=a7 border=0 cellspacing=0 cellpadding=0 width=624 style='border-collapse:collapse;mso-table-layout-alt:fixed;mso-yfti-tbllook:
 1536;mso-padding-alt:5.0pt 5.0pt 5.0pt 5.0pt'>
                  <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
                    <td width=624 valign=top style='width:468.0pt;background:#333333;padding:
  5.0pt 5.0pt 5.0pt 5.0pt'>
                      <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
  8.0pt;margin-left:0cm;line-height:150%;mso-pagination:none;border:none;
  mso-padding-alt:31.0pt 31.0pt 31.0pt 31.0pt;mso-border-shadow:yes'><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>{<br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#D36363;background:#333333'>0</span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman";color:white;
  background:#333333'>:{<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_train_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_train_array</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_test_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_test_array</span><br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span>},<br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#D36363;background:#333333'>1</span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman";color:white;
  background:#333333'>:{<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_train_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_train_array</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_test_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_test_array</span><br>
                          <br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span>}<br>
                          } </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman"'>
                          <o:p></o:p>
                        </span></p>
                    </td>
                  </tr>
                </table>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span class=SpellE><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
color:white;background:#333333'>x_validation_dataframe</span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: It has feature dataframe for validation data set.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span class=SpellE><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
color:white;background:#333333'>y_validation_dataframe</span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: It has the dependent variable, stored as a dataframe for
                    the validation data set.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>model</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: It is the initialized model, stored as an object. For
                    example, for the linear regression function in the Sklearn python library, the
                    model object can be initialized as <span style='color:white;background:#333333'>model
                      = LinearRegression()</span>
                    <o:p></o:p>
                  </span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>This object <span style='color:white;
background:#333333'>model</span> will then be used for training the model by
                    using training data and predicting for test and validation data. It should have
                    a <span style='color:white;background:#333333'>.fit</span> attribute for
                    training, and a <span style='color:white;background:#333333'>.predict</span>
                    attribute for predicting. Sklearn models, as well as Xgboost and other major
                    modeling techniques, have these 2 functionalities. It does not support deep
                    learning models, however.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>cost_function_improvement</span><span lang=EN
                    style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: There are 2 values for this parameter, depending on the
                    goal of the optimization. We can select either &nbsp;increase&nbsp; or &nbsp;decrease&nbsp; as the
                    string
                    value.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Setting the value for &nbsp;increase&nbsp;
                    will enable the feature selection algorithm to look for solutions where model
                    metric values increase in each iteration. One example can be f1 score for
                    classification model. We will like to obtain a model that gives us highest F1
                    score.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Setting the value as &nbsp;decrease&nbsp; will
                    enable the feature selection algorithm to search for solutions where cost is
                    lowest. For example, for regression models, RMSE is a commonly used cost
                    function. It is desirable to obtain a model which has lowest amount of RMSE.
                    Setting &nbsp;decrease&nbsp; for this parameter will enable the algorithm to search for a
                    feature set which gives lowest RMSE.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>cost_function</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: Cost function is for finding cost between actual and
                    predicted values. For a regression problem, some examples are root mean square
                    error, mean absolute error, etc. For a classification problem, some examples
                    are f1 score, precision, and recall. The cost function should have 2 input
                    parameters 'actual' and 'predicted' as arrays. It should return the cost
                    between actual and predicted values. It supports all the cost functions
                    available in Sklearn.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>It also supports custom-made cost
                    functions, as long as there are 2 parameters in the cost function, actual
                    value, followed by predicted values, and returns cost value.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>average</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
"Times New Roman"'>: In the case of multi-class classification problems, cost
                    functions such as precision, recall, f1 score, etc. in Sklearn have a parameter
                    &nbsp;average&nbsp;. This criterion specifies the type of averaging to be used for the
                    cost function if the dependent variable has multiple classes. We can assign the
                    average value for Sklearn cost functions for multi-class classifications in
                    this parameter.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>Now let&nbsp;s initialize a feature
                    selection object for a regression problem, where we will use a linear
                    regression model with 3 features, and mean squared error as a cost function.<o:p></o:p></span></p>

                <table class=a8 border=0 cellspacing=0 cellpadding=0 width=624 style='border-collapse:collapse;mso-table-layout-alt:fixed;mso-yfti-tbllook:
 1536;mso-padding-alt:5.0pt 5.0pt 5.0pt 5.0pt'>
                  <tr style='mso-yfti-irow:0;mso-yfti-firstrow:yes;mso-yfti-lastrow:yes'>
                    <td width=624 valign=top style='width:468.0pt;background:#333333;padding:
  5.0pt 5.0pt 5.0pt 5.0pt'>
                      <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
  8.0pt;margin-left:0cm;line-height:150%;mso-pagination:none;border:none;
  mso-padding-alt:31.0pt 31.0pt 31.0pt 31.0pt;mso-border-shadow:yes'><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>from</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> <span class=SpellE>Sklearn.metrics</span> </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>import</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'> <span class=SpellE>mean_squared_error</span><br>
                        </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>from</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> <span class=SpellE>Sklearn.linear_model</span>
                        </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>import</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'> LinearRegression<br>
                        </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#FCC28C;background:#333333'>from</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> MetaheuristicsFS </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#FCC28C;background:#333333'>import</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'> FeatureSelection<br>
                          <br>
                          <br>
                          columns_list = [</span><span lang=EN style='font-family:"Times New Roman",serif;
  mso-fareast-font-family:"Times New Roman";color:#A2FCA2;background:#333333'>'feature
                          1'</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>, </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#A2FCA2;background:#333333'>'feature2'</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:white;background:#333333'>, </span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman";color:#A2FCA2;
  background:#333333'>'feature 3'</span><span lang=EN style='font-family:"Times New Roman",serif;
  mso-fareast-font-family:"Times New Roman";color:white;background:#333333'>]<br>
                          <br>
                          data_dict = {<br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#D36363;background:#333333'>0</span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman";color:white;
  background:#333333'>:{<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_train_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_train_array</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_test_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_test_array</span><br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span>},<br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:"Times New Roman";
  color:#D36363;background:#333333'>1</span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman";color:white;
  background:#333333'>:{<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_train_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_train&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_train_array</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;x_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>x_test_dataframe</span>,<br>
                          <span
                            style='mso-tab-count:2'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span></span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>&quot;y_test&quot;</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>:<span class=SpellE>y_test_array</span><br>
                          <br>
                          <span
                            style='mso-tab-count:1'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                          </span>}<br>
                          }<br>
                          <br>
                          model = LinearRegression()<br>
                          <br>
                          <span class=SpellE>fsObj</span> = FeatureSelection(columns_list = <span
                            class=SpellE>columns_list,data_dict</span> = data_dict, <span
                            class=SpellE>x_validation_dataframe</span>
                          = <span class=SpellE>x_validation_tree</span>, <span
                            class=SpellE>y_validation_dataframe</span>
                          = <span class=SpellE>y_validation_tree</span>, model = model, cost_function_improvement
                          = </span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:#A2FCA2;background:#333333'>'decrease'</span><span lang=EN style='font-family:"Times New Roman",serif;mso-fareast-font-family:
  "Times New Roman";color:white;background:#333333'>, cost_function = <span
                            class=SpellE>mean_squared_error</span>)</span><span lang=EN style='font-family:
  "Times New Roman",serif;mso-fareast-font-family:"Times New Roman"'>
                          <o:p></o:p>
                        </span></p>
                    </td>
                  </tr>
                </table>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>After the feature selection object
                    has been initialized, it can be used for executing a specified metaheuristic
                    algorithm. Before we get into metaheuristic algorithms, let's understand why we
                    need these algorithms in the first place by going through the first section of
                    the chapter &nbsp;exhaustive feature selection&nbsp;.<o:p></o:p></span></p>
              </div>
            </section>

          </div>
        </div>
      </div>
      <a href="chapter0710.html" class="navigation navigation-prev " aria-label="Previous page"><i
          class="fa fa-angle-left"></i></a>
      <a href="chapter0801.html" class="navigation navigation-next " aria-label="Next page"><i
          class="fa fa-angle-right"></i></a>
    </div>
  </div>
  <script src="libs/gitbook-2.6.7/js/app.min.js"></script>
  <script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
  <script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>


   <script>
    gitbook.require(["gitbook"], function (gitbook) {
      gitbook.start({
        "search": {
          "engine": "fuse",
          "options": null
        },
        "info": false
      });
    });
  </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      var src = "true";
      if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
      if (location.protocol !== "file:")
        if (/^https?:/.test(src))
          src = src.replace(/^https?:/, '');
      script.src = src;
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
</body>

</html>