<!DOCTYPE html>
<html lang="" xml:lang="">

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Before we start | Feature Engineering & Selection for Explainable Models A Second Course for Data
    Scientists
  </title>
  
  
  <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
  <link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
  <link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
  <link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
  <link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
  <script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
  <script src="libs/kePrint-0.0.1/kePrint.js"></script>
  <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
 <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-13135504-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-13135504-1');
</script>
<!-- End Google tag (gtag.js) -->
   

  <link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
  <script src="javascript/cookieconsent.min.js"></script>
  <script>
    window.addEventListener("load", function () {
      window.cookieconsent.initialise({
        "palette": {
          "popup": {
            "background": "#000"
          },
          "button": {
            "background": "#f1d600"
          }
        },
        "position": "bottom-right",
        "content": {
          "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
        }
      })
    });
  </script>

  <style>
    #cta-button-desktop:hover,
    #cta-button-device:hover {
      background-color: #ffc266;
      border-color: #ffc266;
      box-shadow: none;
    }

    #cta-button-desktop,
    #cta-button-device {
      color: white;
      background-color: #ffa31a;
      text-shadow: 1px 1px 0 #444;
      text-decoration: none;
      border: 2px solid #ffa31a;
      border-radius: 10px;
      position: fixed;
      padding: 5px 10px;
      z-index: 10;
    }

    #cta-button-device {
      box-shadow: 0px 10px 10px -5px rgba(194, 180, 190, 1);
      display: none;
      right: 20px;
      bottom: 20px;
      font-size: 20px;
    }

    #cta-button-desktop {
      box-shadow: 0px 20px 20px -10px rgba(194, 180, 190, 1);
      display: display;
      padding: 8px 16px;
      right: 40px;
      bottom: 40px;
      font-size: 25px;
    }

    @media (max-width : 450px) {
      #cta-button-device {
        display: block;
      }

      #cta-button-desktop {
        display: none;
      }
    }
  </style>






  <link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>





  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

        <ul class="summary">
          <li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i
                class="fa fa-check"></i>Summary</a></li>
          <li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a href="foreward.html"><i
                class="fa fa-check"></i>Foreward</a></li>

          <li class="chapter" data-level="1" data-path="intro.html"><a href="before-we-start.html"><i
                class="fa fa-check"></i>Before we start</a></li>
          <li class="chapter" data-level="1"><a href="section-1.html"><i class="fa fa-check"></i>Section I:
              Introduction</a>

          <li class="chapter" data-level="1"><a href="introduction.html"><i class="fa fa-check"></i>1: Introduction</a>
          </li>

          <ul>
            <li class="chapter" data-level="2"><a href="terminology.html"><i class="fa fa-check"></i>1.1:
                Terminology</a></li>
            <li class="chapter" data-level="2"><a href="training-a-model.html"><i class="fa fa-check"></i>1.2: Process of
                Training a Machine Learning Model</a></li>
            <li class="chapter" data-level="2"><a href="preventing-overfitting.html"><i class="fa fa-check"></i>1.3: Preventing
                Overfitting</a></li>
            <li class="chapter" data-level="2"><a href="code-conventions.html"><i class="fa fa-check"></i>1.4: Code
                Conventions</a></li>
            <li class="chapter" data-level="2"><a href="datasets-used.html"><i class="fa fa-check"></i>1.5: Datasets
                Used</a></li>
            <li class="chapter" data-level="2"><a href="chapter1-references.html"><i class="fa fa-check"></i>1.6:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>Section II:
              Feature Engineering</a>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>2: Domain Specific
              Feature Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>2.1:
                Introduction</a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>2.2:
                Domain-Specific Feature Engineering </a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>2.3:
                References</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>3: EDA Feature
              Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>3.1:
                Introduction</a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>3.2: Car Sales
              </a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>3.3: Coupon
                Recommendation</a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>3.4:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>4: Higher Order
              Feature Engineering </a>
          </li>
          <ul>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>4.1:
                Engineering Categorical Features</a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>4.2:
                Engineering Ordinal Features </a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>4.3:
                Engineering Numerical Features</a></li>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>4.4:
                Conclusion</a></li>
          </ul>
            <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>5: Interaction
                Effect Feature Engineering</a>
            </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>5.1:
                Interaction Plot</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>5.2: SHAP</a>
            </li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>5.3: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>5.4:
                Conclusion</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>5.5:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>Section III:
              Feature Selection</a>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>6: Fundamentals of
              Feature Selection</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>6.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>6.2: Different
                Feature Selection Methods</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>6.3: Filter
                Method</a></li>
            <li class="chapter" data-level="2.4"><a href="restricted.html"><i class="fa fa-check"></i>6.4: Wrapper
                Method</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>6.5: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>6.6:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>7: Feature
              Selection Concerning Modeling Techniques</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>7.1:
                Lasso, Ridge, and ElasticNet</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>7.2: Feature
                Importance of Tree Models</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>7.3: Boruta</a>
            </li>
            <li class="chapter" data-level="2.4"><a href="restricted.html"><i class="fa fa-check"></i>7.4: Using
                Tree-Based Feature Importance for Linear Model</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.5: Using
                Linear Model Feature Importance for Tree Models</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.6: Linear
                Regression</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.7: SVM</a>
            </li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.8: PCA</a>
            </li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.9: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>7.10:
                Conclusion</a></li>
          </ul>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>8: Feature
              Selection Using Metaheuristic Algorithms</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>8.1: Exhaustive
                Feature Selection</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>8.2: Genetic
                Algorithm</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>8.3: Simulated
                Annealing</a></li>
            <li class="chapter" data-level="2.4"><a href="restricted.html"><i class="fa fa-check"></i>8.4: Ant Colony
                Optimization</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>8.5: Particle
                Swarm Optimization</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>8.6: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>8.7:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>8.8:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>Section IV:
              Model Explanation</a>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>9: Explaining Model
              and Model Predictions to Layman</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>9.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>9.2:
                Explainable models</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>9.3:
                Explanation Techniques</a></li>
            <li class="chapter" data-level="2.4"><a href="restricted.html"><i class="fa fa-check"></i>9.4: Putting
                Everything Together</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>9.5:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>9.6:
                References</a></li>
          </ul>
          </li>
          <li class="chapter" data-level="1"><a href="restricted.html"><i class="fa fa-check"></i>Section V:
              Special Chapters</a>
          <li class="chapter" data-level="2"><a href="restricted.html"><i class="fa fa-check"></i>10: Feature
              Engineering & Selection for Text Classification</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="restricted.html"><i class="fa fa-check"></i>10.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="restricted.html"><i class="fa fa-check"></i>10.2: Feature
                Construction</a></li>
            <li class="chapter" data-level="2.3"><a href="restricted.html"><i class="fa fa-check"></i>10.3: Feature
                Selection</a></li>
            <li class="chapter" data-level="2.4"><a href="restricted.html"><i class="fa fa-check"></i>10.4: Feature
                Extraction</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>10.5: Feature
                Reduction</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>10.6:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="restricted.html"><i class="fa fa-check"></i>10.7:
                References</a></li>
          </ul>
          <li class="chapter" data-level="2"><a href="baseline-removal-python.html"><i class="fa fa-check"></i>11: Things That Can
              Give Additional Improvement</a>
          </li>
          <ul>
            <li class="chapter" data-level="2.1"><a href="baseline-removal-python.html"><i class="fa fa-check"></i>11.1:
                Introduction</a></li>
            <li class="chapter" data-level="2.2"><a href="hyperparameter-tuning.html"><i class="fa fa-check"></i>11.2:
                Hyperparameter Tuning</a></li>
            <li class="chapter" data-level="2.3"><a href="ensemble-learning.html"><i class="fa fa-check"></i>11.3: Ensemble
                Learning</a></li>
            <li class="chapter" data-level="2.4"><a href="signal-processing-machine-learning.html"><i class="fa fa-check"></i>11.4: Signal
                Processing</a></li>
            <li class="chapter" data-level="2.5"><a href="conclusion.html"><i class="fa fa-check"></i>11.5:
                Conclusion</a></li>
            <li class="chapter" data-level="2.5"><a href="references.html"><i class="fa fa-check"></i>11.6:
                References</a></li>
          </ul>
          </li>
        </ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
          </h1>
        </div>
        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
              <div id="forward-by-the-author" class="section level1 hasAnchor" number="1">
                <h1>Before we start</h1>
                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>Are you a budding machine learning engineer using Python, wondering what steps to take after mastering the basics? Perhaps you're a researcher exploring traditional machine learning algorithms for your thesis, a data scientist in your first role seeking to elevate model performance, or a leader transitioning into data science who wants to confidently engage with technical teams. This book is crafted precisely for you. It serves as a second course, aiming to answer the pressing question: "What do I do now to improve my machine learning models?"<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>Our goal is to make you self-sufficient in the fine art of developing highly accurate machine learning models that are production-ready. We'll guide you through the different stages of a machine learning project—from advanced feature engineering to comprehensive model explanation. By learning these fundamental building blocks, you'll become a better-educated machine learning engineer, a more insightful researcher, a capable consultant, and a confident leader in the field of artificial intelligence and machine learning.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>This book is neither heavy on mathematical notation nor overloaded with code. Instead, we focus on explaining theoretical nuances, often aided by plots and analysis results, to provide a hands-on feel of projects from inception to completion. Supplemental code is available on the accompanying GitHub page, allowing you to delve deeper into how each analysis was conducted.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>We've organized the content to mirror the practical execution of a machine learning project, starting from feature engineering and moving towards model explanation. In Chapter 11, we delve into methods beyond traditional feature engineering and selection, introducing denoising techniques for signal processing data. While we cover multiple approaches to improving model performance, it's important to acknowledge that there's no silver bullet in machine learning. Even after employing techniques like feature engineering, feature extraction, feature selection, and ensembling, you might not achieve the desired model performance. Factors like data inadequacy and quality issues—topics beyond the scope of this book—can lead to project challenges. To illustrate these points, we'll examine four example datasets: two showcasing machine learning successes and two highlighting failure scenarios.<o:p></o:p>
                  </span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>Deep learning models often eliminate the need for feature engineering, especially with unstructured data like images, text, audio, and video. However, for structured tabular data, mastering feature engineering and knowing how to enrich your dataset by creating higher-level features from original ones is crucial. Understanding which features to retain can decisively impact your project's outcome. This book makes a sincere attempt to educate you on these different steps involved in training a machine learning model within the realms of feature engineering and feature selection.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>We assume you're already familiar with fundamental concepts like regression and classification, as well as common machine learning techniques such as linear regression, random forests, and logistic regression. You should also be comfortable with different cost functions like Root Mean Square Error (RMSE), F1 score, precision, and recall. This book is tailored for those who have tried their hand at developing models and are seeking guidance to elevate model performance to higher levels.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>Although the concepts discussed are applicable across various programming languages, this book is specifically written for Python users. To support this, several algorithms mentioned have been developed from scratch and open-sourced as four separate Python libraries by the author. We expect you to have a basic understanding of libraries like Scikit-learn for machine learning, Pandas and NumPy for data manipulation, and Matplotlib and Seaborn for data visualization.<o:p></o:p></span></p>

                <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
                8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
                mso-fareast-font-family:"Times New Roman"'>For experienced consultants, we introduce methods and techniques that are less commonly heard of or used, including those that were not previously available in Python. For leaders in data science, this book will help you gain perspective on how to advocate for your models by utilizing model explainability techniques.<o:p></o:p></span></p>
              <p class=MsoNormal style='margin-top:16.0pt;margin-right:0cm;margin-bottom:
8.0pt;margin-left:0cm;line-height:150%'><span lang=EN style='font-family:"Times New Roman",serif;
mso-fareast-font-family:"Times New Roman"'>It's important to note that this book focuses on model development after data cleaning has been performed and you have a clean dataset. We do not cover how to clean data, handle outliers, or deal with missing data. Numerous valuable resources already exist on these topics, and they are outside the scope of this book.<o:p></o:p></span></p>

              </div>
          </div>
          </section>

        </div>
      </div>
      <a href="foreward.html" class="navigation navigation-prev " aria-label="Previous page"><i
          class="fa fa-angle-left"></i></a>
      <a href="section-1.html" class="navigation navigation-next " aria-label="Next page"><i
          class="fa fa-angle-right"></i></a>
    </div>
  </div>
  <script src="libs/gitbook-2.6.7/js/app.min.js"></script>
  <script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
  <script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
  <script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
  

   <script>
    gitbook.require(["gitbook"], function (gitbook) {
      gitbook.start({
        "search": {
          "engine": "fuse",
          "options": null
        },
        "info": false
      });
    });
  </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      var src = "true";
      if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
      if (location.protocol !== "file:")
        if (/^https?:/.test(src))
          src = src.replace(/^https?:/, '');
      script.src = src;
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
</body>

</html>